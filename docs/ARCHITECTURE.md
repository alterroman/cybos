# SerokellSalesAgent Architecture

*Technical reference for the SerokellSalesAgent system*

---

## System Overview

SerokellSalesAgent is a Claude Code-powered personal AI assistant for an individual user and an operations aid for their organization. It handles three core domains:

| Domain | Capability |
|--------|------------|
| **Research** | Company DD, technology deep-dives, market analysis, topic exploration |
| **Browse** | Discover trending topics from social feeds (Twitter) |
| **Brief** | Morning brief consolidating Telegram, emails, calendar, and GTD |
| **Email** | Process Gmail for VC deal flow, draft replies, save attachments to deals |
| **Telegram** | Process unread messages via GramJS MTProto, draft replies, save drafts |
| **Content** | Tweets, essays, images (following brand guidelines) |
| **DD Memo** | Investment memo generation from templates |
| **GTD** | Autonomous task execution from GTD.md with entity context |
| **Summarize** | Summarize transcripts (therapy sessions, meetings) into structured notes |

**Key Design Principles:**
- File-first: All state is markdown on disk or is accessible via MCP tools and scripts (Gmail, Telegram, Granola, Asana, etc)
- Scaffolding > prompting: Workflows + tools beat raw prompts
- Slash commands for execution
- Single-file logging after every workflow
- Context auto-loading: Deal context loads automatically when mentioned
- Single-user, no scheduled automation (MVP)

---

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SEROKELL                            â”‚
â”‚              (Claude Code + .claude folder)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    SKILLS     â”‚   â”‚    AGENTS     â”‚   â”‚     HOOKS     â”‚
â”‚ (Convention)  â”‚   â”‚ (Task tool)   â”‚   â”‚ ContextLoad   â”‚
â”‚ Research      â”‚   â”‚ Researchers   â”‚   â”‚ ActionLog     â”‚
â”‚ Browse        â”‚   â”‚ Writers       â”‚   â”‚ DBFreshness   â”‚
â”‚ Telegram      â”‚   â”‚ Analysts      â”‚   â”‚               â”‚
â”‚ Content       â”‚   â”‚               â”‚   â”‚               â”‚
â”‚ DDMemo        â”‚   â”‚               â”‚   â”‚               â”‚
â”‚ GTD           â”‚   â”‚               â”‚   â”‚               â”‚
â”‚ Summarize     â”‚   â”‚               â”‚   â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                   â”‚                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CONTEXT LAYER                        â”‚
â”‚  /context/*         (identity, philosophy, brand, style)â”‚
â”‚  /context/entities/ (people, orgs - sparse files)       â”‚
â”‚  /deals/*           (per-company research + memos)      â”‚
â”‚  /research/*        (topic/market research)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MCP SERVERS  â”‚   â”‚    SQLite     â”‚   â”‚    OUTPUTS    â”‚
â”‚ Perplexity    â”‚   â”‚  (FTS5)       â”‚   â”‚ /deals/       â”‚
â”‚ Exa / Parallelâ”‚   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   â”‚ /research/    â”‚
â”‚ Firecrawl     â”‚   â”‚ entities      â”‚   â”‚ /content/     â”‚
â”‚ Playwright    â”‚   â”‚ interactions  â”‚   â”‚               â”‚
â”‚ Notion        â”‚   â”‚ extracted_    â”‚   â”‚ /.serokell/   â”‚
â”‚ Nano Banana   â”‚   â”‚   items       â”‚   â”‚ logs/         â”‚
â”‚ Typefully     â”‚   â”‚               â”‚   â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Configuration System (v2.1)

Starting with v2.1, SerokellSalesAgent uses a global configuration system that separates code from data.

### Configuration Location

```
~/.serokell/                          # Global config directory
  config.json                      # Main configuration file

~/SerokellSalesVault/                      # User data vault (configurable path)
  private/                         # Local-only data
    .serokell/
      logs/                        # All logs (activity, daemon, script)
      db/serokell.sqlite              # Context graph database
    context/                       # Core context files
    deals/                         # Deal folders
    research/                      # Topic/market research
    projects/                      # Multi-week initiatives
    content/                       # Generated content
  shared/                          # Team-shared data (optional)

cyberman/                          # Application directory
  vault -> ~/SerokellSalesVault            # Symlink for IDE access (created by setup wizard)
```

### IDE Workflow

The `vault` symlink allows editing vault files directly in your IDE:
- Open `cyberman` folder in VS Code or Cursor
- Vault files appear as `vault/private/` and `vault/shared/` in the sidebar
- Run Claude Code from the same directory
- **Ignored by git** - Your data won't be committed

### Config Schema

Location: `~/.serokell/config.json`

```json
{
  "version": "2.1",
  "vault_path": "~/SerokellSalesVault",
  "app_path": "~/Work/cyberman",
  "private": {
    "git_enabled": false,
    "repo_url": null
  },
  "shared": {
    "enabled": false,
    "repo_url": null
  },
  "user": {
    "name": "Your Name",
    "owner_name": "YourName",
    "slug": "your-name",
    "aliases": ["Me", "Your Name"]
  },
  "setup_completed": true,
  "automations": {
    "daily_reindex": true,
    "daily_brief": true
  }
}
```

**Notes:**
- `app_path` points to where SerokellSalesAgent code is installed (set during setup). Skills use this to locate scripts.
- API keys remain in `.env` file for security (not in config JSON).

### Configuration Scripts

| Script | Purpose |
|--------|---------|
| `scripts/config.ts` | Config loading, saving, validation, version migration |
| `scripts/paths.ts` | Centralized path resolution for vault and app locations |

### Path Resolution

All scripts should use `scripts/paths.ts` for file paths:

```typescript
import { getDealsPath, getLogsPath, getDbPath } from './paths'

const deals = getDealsPath()      // ~/SerokellSalesVault/private/deals
const logs = getLogsPath()        // ~/SerokellSalesVault/private/.serokell/logs
const db = getDbPath()            // ~/SerokellSalesVault/private/.serokell/db/serokell.sqlite
```

### Legacy Mode

During transition, the system supports legacy mode (no vault):
- If config doesn't exist and `context/`, `deals/` exist in app root â†’ legacy mode
- Scripts use `isLegacyMode()` to detect and `getPathWithLegacyFallback()` for compatibility

### Vault Sync Scripts

| Script | Purpose | Usage |
|--------|---------|-------|
| `scripts/vault-sync.sh` | Sync vault repos to GitHub | `./scripts/vault-sync.sh [private\|shared\|all]` |
| `scripts/move-to-share.sh` | Move deal/research to shared vault | `./scripts/move-to-share.sh deal acme-corp` |

**Vault sync operations:**
```bash
./scripts/vault-sync.sh private     # Sync private vault only
./scripts/vault-sync.sh shared      # Sync shared vault only
./scripts/vault-sync.sh             # Sync both (default)
./scripts/vault-sync.sh --status    # Show status of both repos
./scripts/vault-sync.sh --pull      # Pull only (no push)
```

**Moving data to shared:**
```bash
./scripts/move-to-share.sh deal acme-corp       # Move deal
./scripts/move-to-share.sh research ai-market   # Move research
```

**Gitignore templates:**
- `config/vault-private.gitignore` - Template for private vault
- `config/vault-shared.README.md` - README template for shared vault

### Setup Wizard

If config is missing when a command runs:
1. Auto-start brief-server if not running
2. Open browser to `http://localhost:3847/setup`
3. Command exits with helpful message

---

## Skill System

**Skills are a convention, not a Claude Code feature.** The `.claude/skills/` directory is an organizational pattern. Skill files are markdown documents that get loaded via:
- `@file` references in slash commands
- Explicit file reads during workflows
- Hook injection (for core identity only)

Claude Code doesn't have a native "skill loader" â€” we create this behavior through structured commands and workflows.

### Skill Locations

```
.claude/skills/
â”œâ”€â”€ Research/
â”‚   â”œâ”€â”€ workflows/      # orchestrator.md (universal workflow)
â”‚   â””â”€â”€ shared/         # agent-selection-matrix.md, investment-lens.md, etc.
â”œâ”€â”€ Browse/
â”‚   â””â”€â”€ workflows/      # twitter-feed.md (discover topics from feeds)
â”œâ”€â”€ Email/
â”‚   â””â”€â”€ workflows/      # process-gmail.md (via /serokell-email command)
â”œâ”€â”€ Telegram/
â”‚   â””â”€â”€ workflows/      # process-messages.md (read, draft, save via GramJS)
â”œâ”€â”€ Content/
â”‚   â””â”€â”€ workflows/      # telegram-post.md (primary), tweet.md, essay.md, image.md, schedule.md
â”œâ”€â”€ DDMemo/
â”‚   â””â”€â”€ workflows/      # generate.md
â”œâ”€â”€ GTD/
â”‚   â”œâ”€â”€ SKILL.md        # Main entry point with classification + routing
â”‚   â”œâ”€â”€ workflows/      # outreach.md, call-prep.md, podcast.md, research.md
â”‚   â””â”€â”€ learnings.md    # Action log for pattern analysis
â”œâ”€â”€ Summarize/
â”‚   â””â”€â”€ workflows/      # therapy.md (therapy session transcripts)
â”œâ”€â”€ Self-improve/
â”‚   â””â”€â”€ SKILL.md        # Always-active napkin for tracking mistakes/patterns
â””â”€â”€ baoyu-infographic/
    â”œâ”€â”€ SKILL.md        # 20 layouts Ã— 17 styles infographic generator
    â””â”€â”€ references/     # Layout definitions, style definitions, templates
```

### Self-Improve Skill (Napkin)

**Always active.** Maintains `.claude/napkin.md` for tracking mistakes, corrections, and patterns.

**Session behavior:**
1. Read napkin at session start (before doing anything)
2. Apply learnings silently (don't announce)
3. Update continuously as you work (not just at end)

**Log when:**
- You hit an error and figure out why
- User corrects you
- You catch your own mistake
- An approach fails or succeeds unexpectedly

**Napkin structure:**
```markdown
# Napkin

## Corrections
| Date | Source | What Went Wrong | What To Do Instead |

## User Preferences
## Patterns That Work
## Patterns That Don't Work
## Domain Notes
```

**Maintenance:** Consolidate every 5-10 sessions when >150 lines. Keep under 200 lines of high-signal content.

---

### Research Shared Content

Research skill uses **progressive disclosure** pattern with shared reference files in `.claude/skills/Research/shared/`:

- `agent-selection-matrix.md` - Dynamic agent selection based on research type + intensity
- `investment-lens.md` - organization investment philosophy and rubric
- `mcp-strategy.md` - MCP tool selection by intensity tier
- `error-handling.md` - Error recovery and data quality handling
- `output-standards.md` - Standardized emoji-based output formats
- `intensity-tiers.md` - Complete 3-tier intensity system spec
- `logging.md` - Research debugging and MCP usage logging

---

## Agent System

Agents are spawned via Claude Code's `Task` tool. Multiple Task calls in the same response enable **parallel execution**.

### Agent Definitions

| Agent | Model | Purpose |
|-------|-------|---------|
| `company-researcher` | Haiku | Company-specific data gathering (business, product, traction) |
| `market-researcher` | Haiku | Market dynamics, TAM, competitive landscape, timing |
| `financial-researcher` | Haiku | Funding history, metrics, valuation, unit economics |
| `team-researcher` | Haiku | Founder backgrounds, team assessment, energy/speed |
| `tech-researcher` | Haiku | Technology deep-dives, moat analysis, maturity |
| `content-researcher` | Haiku | Topic research via academic papers, social media, first-principles (for content) |
| `investment-researcher` | Haiku | Topic research via market dynamics, opportunities, timing (for investment) |
| `quality-reviewer` | Sonnet | Gap analysis, contradiction detection, follow-up identification (deep mode only) |
| `content-writer` | Sonnet | Tweets, essays, drafts |
| `memo-analyst` | Opus | Strategic investment analysis |
| `memo-writer` | Sonnet | Memo generation from template |
| `synthesizer` | Sonnet | Consolidate parallel agent outputs |

**Agent Output Format**: All research agents use standardized emoji-based format:
- ğŸ” Starting | ğŸ“Š Data | ğŸ’¡ Insights | âœ… Strengths | âš ï¸ Concerns | ğŸ”— Sources | ğŸ¯ Completion

### Parallel Execution Pattern

To run agents in parallel, issue multiple Task calls in the same response:

```
[Task: company-researcher] Research Acme Corp business model
[Task: market-researcher] Research Acme Corp's market
[Task: financial-researcher] Research Acme Corp funding
[Task: team-researcher] Research Acme Corp founders
```

Agent profiles are stored in `.claude/agents/*.md`.

---

## Context System

### Context Loading Strategy

| Context Type | Loading Method | When |
|--------------|----------------|------|
| **Identity** | SessionStart hook | Every session |
| **Workflows** | `@file` in slash commands | Per-command |
| **Deal-specific** | Auto-pulled when deal mentioned | On-demand |

### Deal Context Structure

```
/deals/<company>/
â”œâ”€â”€ .serokell/
â”‚   â”œâ”€â”€ context.md        # Deal metadata, status, key contacts
â”‚   â””â”€â”€ scratchpad/       # Temp agent working files
â”œâ”€â”€ research/
â”‚   â””â”€â”€ MMDD-<slug>-YY.md # Research reports (load latest)
â””â”€â”€ memo/
    â””â”€â”€ memo.md           # Current memo
```

### Deal Context Template

```markdown
# Deal: [Company Name]

**Status:** [Sourced | Researching | DD | IC | Passed | Invested]
**Stage:** [Pre-seed | Seed | Series A | ...]
**First Contact:** MMDD-YY
**Lead:** [Partner name]

## Key Contacts
- Founder: [Name] ([email])

## Quick Facts
- Raising: $X at $Y valuation
- Sector: [AI Infra | Crypto | Robotics | ...]
- Thesis fit: [Notes on how this fits organization focus]

## Open Questions
- [Question 1]

## Notes
[Running notes from calls, research, etc.]
```

---

## Granola Call Extraction

SerokellSalesAgent extracts meeting transcripts and AI notes from Granola.

### How It Works

- **Auto-extraction**: SessionStart hook runs incremental extraction (only new calls)
- **Manual trigger**: `/serokell-save-calls` command
- **Data source**: `~/Library/Application Support/Granola/cache-v3.json`
- **Output**: `/context/calls/[MMDD]-[title]-[YY]/` with transcript.txt, notes.md, metadata.json
- **Database**: Call interactions indexed in SQLite via `/serokell-reindex`

### Output Structure

```
/context/calls/
â”œâ”€â”€ README.md             # Usage documentation
â””â”€â”€ MMDD-title-YY/        # Individual call folders
    â”œâ”€â”€ metadata.json
    â”œâ”€â”€ transcript.txt
    â””â”€â”€ notes.md
```

---

## Telegram GramJS Integration

SerokellSalesAgent processes Telegram messages via GramJS MTProto client (not browser automation).

### How It Works

- **Script-based**: `scripts/telegram-gramjs.ts` connects directly to Telegram API
- **Per-person files**: Each contact has persistent conversation file (`context/telegram/<slug>.md`)
- **Entity integration**: Looks up entities by telegram username via database
- **Manual trigger**: `/serokell-telegram` command
- **Authentication**: First run prompts for phone + code, session saved to `~/.serokell/telegram/`
- **Read-only by default**: Never sends messages, only saves drafts
- **Smart filtering**: Skips archived and muted chats automatically

### Modes

| Mode | Flag | Description |
|------|------|-------------|
| **Unread** (default) | `--count N` | Process N unread conversations |
| **User** | `--user "name"` | Find specific person by username/name (any read state) |
| **Requests** | `--requests` | Process message requests folder (non-contacts who messaged you) |

```bash
# Unread mode (default)
/serokell-telegram                    # 1 unread dialog
/serokell-telegram --count 3          # 3 unread dialogs

# User mode (any read state)
/serokell-telegram --user "@username" # By Telegram username
/serokell-telegram --user "Name"      # By name

# Requests mode (non-contacts)
/serokell-telegram --requests         # Message requests folder

# Modifiers
/serokell-telegram --dry-run          # Read only, no drafts saved
/serokell-telegram --no-mark-unread   # Don't preserve unread state
```

### Workflow

1. Script fetches dialogs based on mode (unread, user search, or requests)
2. Reads last 20 messages per dialog (both directions)
3. Looks up entity by telegram username in SQLite database
4. Gets/creates per-person file: `context/telegram/<slug>.md`
5. Deduplicates: only appends messages with ID > lastMessageId
6. Creates work file:
   - Unread/requests: `content/work/MMDD-telegram-replies-YY.md`
   - User mode: `content/work/MMDD-telegram-<user-slug>-YY.md`
7. Marks conversations as unread (preserves state)
8. AI generates draft replies
9. User approves, `telegram-save-drafts.ts` saves drafts to Telegram
10. Sent messages captured on next read

**Draft saving script (`scripts/telegram-save-drafts.ts`):**
- Parses work file to extract draft replies
- Matches dialogs using strict strategy:
  1. Dialog ID (primary, e.g., `-1002178089244` for groups)
  2. Exact username match (e.g., `@username`)
  3. Exact title match only (no fuzzy/substring matching)
- Calls `messages.SaveDraft` API for each dialog
- Reports success/failure for each draft saved

### Per-Person Conversation File Format

```markdown
# Anton Lobintsev

**Entity:** anton-lobintsev
**Username:** @lobintsev
**Type:** private
**First contact:** 2026-01-06
**Last updated:** 2026-01-06T14:45:00Z
**Last message ID:** 12345

---

## 2026-01-06

- [12:39] **Anton**: Message text...
- [14:45] **Me**: Reply text...

---
```

**Metadata fields:**
- `Entity:` - links to entity index slug (for cross-reference)
- `Username:` - Telegram handle
- `Type:` - private/group/channel
- `First contact:` - when file was created
- `Last updated:` - when last message was appended
- `Last message ID:` - for deduplication

### Output Structure

```
~/SerokellSalesVault/private/
â”œâ”€â”€ context/telegram/
â”‚   â”œâ”€â”€ README.md                           # Documentation
â”‚   â”œâ”€â”€ anton-lobintsev.md                  # Per-person conversation log
â”‚   â”œâ”€â”€ egor.md                             # Per-person conversation log
â”‚   â””â”€â”€ org-team.md                         # Group chats too
â””â”€â”€ content/work/
    â””â”€â”€ 0106-telegram-replies-26.md         # AI draft replies (GTD-style)

~/.serokell/telegram/
â””â”€â”€ session.txt                             # Auth session (outside git)
```

### Prerequisites

```bash
# .env
TELEGRAM_API_ID=...      # Get from https://my.telegram.org/apps
TELEGRAM_API_HASH=...    # Get from https://my.telegram.org/apps

# Install dependency
bun add telegram
```

### Safety Model

- **Drafts only**: `messages.SaveDraft` API saves draft text, user sends manually in Telegram
- **No read receipts**: Conversations marked unread after processing
- **No auto-send**: AI drafts require user approval before saving
- **Session local**: Auth stored in `~/.serokell/telegram/`, not in git
- **Deduplication**: Messages never duplicated thanks to lastMessageId tracking

---

## Email Indexing System

SerokellSalesAgent indexes emails from Gmail for context and morning brief.

### How It Works

- **Manual trigger**: `/serokell-email --sync` command
- **Data source**: Gmail via `@gongrzhe/server-gmail-autoauth-mcp`
- **Output**: `/context/emails/YYYY-MM-DD_<from>-<subject>/` with metadata.json, body.md
- **Database**: Email interactions indexed in SQLite via `/serokell-reindex`
- **Deduplication**: Via `.state.json` tracking processedMessageIds

### Workflow

1. Load `.state.json` to get already-processed messageIds
2. Query Gmail: `(is:unread OR is:important) after:N_days_ago`
3. Filter out already-processed emails
4. For each new email: read content, generate summary, save to folder
5. Update `.state.json` with new messageIds
6. Run `/serokell-reindex` to index emails in database

### Output Structure

```
/context/emails/
â”œâ”€â”€ README.md             # Documentation
â”œâ”€â”€ .state.json           # Dedup state (messageIds)
â””â”€â”€ YYYY-MM-DD_from-subject/
    â”œâ”€â”€ metadata.json     # Email metadata + AI summary
    â””â”€â”€ body.md           # Email content (markdown)
```

### Index Format

```markdown
| Date | From | Subject | Important | Summary | Path |
|------|------|---------|-----------|---------|------|
| 2026-01-07 | John Smith (john@acme.com) | Series A Update | â­ | Q4 metrics exceeded targets | [ğŸ“](./2026-01-07_john-smith-series-a/) |
```

### Query Strategy

Default sync: `(is:unread OR is:important) after:3_days_ago`
- Prioritizes important emails (marked with â­ in index)
- Designed for headless morning brief automation

---

## Web Brief System

Visual morning brief with scheduled generation and browser display.

### How It Works

- **Scheduled generation**: launchd triggers `/serokell-brief` daily at 8am
- **HTTP server**: Hono server on port 3847 serves API + React app
- **Parser**: Converts brief markdown to structured JSON
- **Web UI**: React + Tailwind app for visual brief display

### Components

```
scripts/
â”œâ”€â”€ brief-parser.ts      # Markdown â†’ JSON parser
â”œâ”€â”€ brief-server.ts      # Hono HTTP server (port 3847)
â”œâ”€â”€ morning-brief.sh     # Orchestrator (generate + server + browser)
â”œâ”€â”€ install-brief.sh     # Installation script for launchd
â”œâ”€â”€ db/query.ts          # Database queries including getExplorerDashboard()
â””â”€â”€ web-brief/           # React + Vite + Tailwind app
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ App.tsx             # Main component with routing
    â”‚   â”œâ”€â”€ types.ts            # TypeScript interfaces (Brief + Explorer)
    â”‚   â”œâ”€â”€ api.ts              # API client
    â”‚   â”œâ”€â”€ components/
    â”‚   â”‚   â””â”€â”€ ItemCard.tsx    # Reusable item display component
    â”‚   â””â”€â”€ pages/
    â”‚       â””â”€â”€ ExplorerPage.tsx # Context Explorer page
    â””â”€â”€ dist/                    # Production build (served by Hono)

config/
â”œâ”€â”€ leverage-rules.yaml        # Strategic leverage scoring rules
â””â”€â”€ launchd/
    â”œâ”€â”€ com.serokell.brief-server.plist.example   # Server daemon template
    â””â”€â”€ com.serokell.morning-brief.plist.example  # 8am daily trigger template
```

### API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/brief/today` | GET | Today's brief as JSON |
| `/api/brief/yesterday` | GET | Yesterday's brief as JSON |
| `/api/brief/:date` | GET | Specific brief (MMDD-YY format) |
| `/api/briefs` | GET | List available briefs |
| `/api/explorer` | GET | Explorer dashboard (deals, entities, items) |
| `/api/health` | GET | Server health check |
| `/*` | GET | Static React app |

### Context Explorer

The Explorer page (`?page=explorer`) provides a dashboard view of extracted items from the context graph database:

**Panels:**
1. **Active Deals** - Auto-detected from deal mentions, fuzzy-grouped by similar names
2. **Recent People** - Entities with recent activity, showing promises and action items
3. **My Commitments** - Pending promises/action items where I am the owner
4. **Metrics Overview** - Metrics grouped by company

**Features:**
- Filter dropdown: All / Promises / Actions / Decisions / Metrics
- Expand/collapse cards for detailed items
- Provenance quotes from source transcripts
- Trust level indicators (high/medium/low)
- 14-day rolling window

**Data flow:**
```
SQLite (context graph) â†’ getExplorerDashboard() â†’ /api/explorer â†’ ExplorerPage.tsx
```

### Strategic Leverage Scoring

The brief includes a "Strategic Leverage" section that scores items by:

1. **Urgency rules** - Message age, meeting proximity, blocking keywords
2. **Leverage rules** - Deal-related, founder/investor communication, intros
3. **Goal-alignment rules** - Based on priorities from `context/who-am-i.md`

Configuration: `config/leverage-rules.yaml`

### Installation

```bash
# Full installation (build + launchd setup)
./scripts/install-brief.sh

# Check status
./scripts/install-brief.sh --status

# Uninstall
./scripts/install-brief.sh --uninstall
```

### Manual Usage

```bash
# Start server manually
bun scripts/brief-server.ts

# Open browser (skip generation)
./scripts/morning-brief.sh --skip-gen

# Just ensure server running
./scripts/morning-brief.sh --server
```

### URLs

- Web UI: http://localhost:3847
- Today's brief: http://localhost:3847?day=today
- Yesterday's brief: http://localhost:3847?day=yesterday
- API Health: http://localhost:3847/api/health

---

## Calendar Integration

SerokellSalesAgent queries Google Calendar via the unified Gmail MCP (which handles both email and calendar).

### How It Works

- **MCP Server**: Unified Gmail MCP (`gmail-mcp`) with built-in OAuth credentials
- **Command**: `/serokell-calendar` - returns today+tomorrow meetings
- **Output**: Markdown tables (ephemeral, not saved)
- **Use case**: Morning brief automation
- **Auth**: Same "Sign in with Google" flow as Gmail - one auth for both

### Output Format

```markdown
## Today (2026-01-07, Tuesday)

| Time | Event | Attendees | Location |
|------|-------|-----------|----------|
| 09:00-10:00 | Team Standup | Sarah, Mike | https://zoom.us/... |
| 14:00-15:00 | Acme Corp DD Call | John Smith | Google Meet |
```

### MCP Tools

```
mcp__gmail__list_calendar_events
  - time_min: ISO 8601 start (optional, defaults to now)
  - time_max: ISO 8601 end (optional)
  - max_results: number (default: 10)
  - query: free text search (optional)

mcp__gmail__create_calendar_event
  - summary: event title
  - start_time: ISO 8601 or natural language ("tomorrow 3pm")
  - end_time: ISO 8601 (optional)
  - description: event notes (optional)
  - location: event location (optional)
  - attendees: list of email addresses (optional)
```

### Headless Execution

Both email sync and calendar are designed for headless execution:
```bash
claude --headless "/serokell-email --sync"
claude --headless "/serokell-calendar"
```

---

## Morning Brief System

SerokellSalesAgent generates comprehensive morning briefs consolidating all data sources.

### How It Works

- **Command**: `/serokell-brief`
- **Output**: `/content/briefs/MMDD-YY.md` (persistent)
- **Data sources**: Telegram, Gmail, Calendar, GTD.md
- **Script dependency**: `scripts/telegram-gramjs.ts --all --summary-only`

### Data Gathering (parallel)

| Source | Method | Output |
|--------|--------|--------|
| Telegram | `bun telegram-gramjs.ts --all --summary-only` | JSON to stdout |
| Email | `mcp__gmail__search_emails` query: `(is:unread OR is:important) after:YYYY/MM/DD` | Message list |
| Calendar | `mcp__gmail__list_calendar_events` with time_min/time_max | Event list |
| GTD | Read `/GTD.md` | Task list |

### Brief Structure

```markdown
# Morning Brief - YYYY-MM-DD

## Priority Actions
[Urgent items requiring immediate attention]

## Today's Schedule
| Time | Event | Attendees | Location |
[Calendar events in table format]

## Messages to Respond
### [Person Name] (@username)
[Full message history - not summaries]

## Email Highlights
| From | Subject | Date |
[Important/unread emails]

## Tasks (from GTD)
- [ ] Task 1
- [ ] Task 2

## Context Loaded
[Entity context, deal references, recent calls]
```

### Key Features

- **Full messages**: Telegram messages included verbatim, not summarized
- **History**: Briefs are persistent in `/content/briefs/`
- **Priority scoring**: Based on meeting urgency, response delay, deal relevance
- **Entity enrichment**: Auto-loads context for mentioned people/companies

### Headless Execution

```bash
claude --headless "/serokell-brief"
```

---

## Unstuck System

Interactive focus/clarity ritual for breaking distraction loops and reconnecting with goals.

### How It Works

- **Command**: `/serokell-unstuck` - Opens browser to web interface
- **Web UI**: `localhost:3847/unstuck` (React + progressive reveal flow)
- **Backend**: `scripts/brief-server.ts` (API endpoints)
  - `GET /api/unstuck/goals` - Returns Active Priorities from `context/who-am-i.md`
  - `POST /api/unstuck/log` - Logs completed session to journal
- **Frontend**: `scripts/web-brief/src/pages/UnstuckPage.tsx`
- **Journal**: `/context/unstuck/journal.md` (append-only log)
- **Goals source**: Parses Active Priorities section from `context/who-am-i.md`

### The Flow

```
1. PAUSE - What's happening?
   - Predefined tags: scattered, avoiding, overwhelmed, bored, anxious, unclear, tired
   - Or write custom state

2. FORK - Did naming it help?
   â†’ Yes â†’ show goals
   â†’ No â†’ dig deeper
   â†’ Need rest â†’ exit gracefully

3. DIG DEEPER (if needed) - Prompts from therapy/coaching:
   - "What might I be protecting myself from?" (IFS)
   - "Where do I feel this in my body?" (Somatic)
   - "What would I do if this feeling wasn't in the way?" (ACT)

4. CONNECT - Show goals from who-am-i.md:
   - What I'm Optimizing For
   - Active Priorities
   - Philosophical Foundation
   - Pick what feels alive

5. CAPTURE - Brief note for pattern tracking

6. RELEASE - "You're clear. Go."
```

### Journal Format

```markdown
## 2026-01-07 14:32

**State:** avoiding
**Needed deeper dig:** Yes
**Deeper dig prompt:** protecting
**Response:** Fear of not being good enough at the research task
**Connected to:** Making ideas real
**Smallest step:** Open the document and write one sentence
**Note:** Realized I avoid research when I'm not sure where to start

---
```

### Design Principles

- **Reconnection over productivity**: Shows WHY layer (goals, values), not WHAT layer (specific tasks)
- **Branching paths**: Quick path when naming helps, deeper dig when it doesn't
- **Permission for rest**: Recognizes that sometimes you need a break, not motivation
- **Self-knowledge over metrics**: Tracks feelings and insights, not productivity stats
- **2-3 minutes max**: Not a therapy session, just enough to reconnect

### Output Structure

```
/context/unstuck/
â”œâ”€â”€ journal.md          # Append-only session log
â””â”€â”€ (future: patterns.md for AI-generated insights)
```

---

## MCP Integrations

### Core MCP Servers

SerokellSalesAgent uses these MCP servers with the following priority hierarchy:

**Primary:**
- **exa**: Web search, company research, URL content extraction (PRIMARY for research)
- **perplexity**: Fast search + deep research with citations
- **parallel-task**: Deep research tasks, report-style outputs
- **nano-banana**: Image generation (Gemini 3.0)

**Fallback:**
- **parallel-search**: Web search + content fetch (fallback for exa)
- **firecrawl**: Scraping and extraction (LAST RESORT ONLY)

**Other:**
- **playwright**: Browser automation
- **notion**: Document storage
- **typefully**: Social media scheduling (Twitter, LinkedIn) âœ…
- **gmail**: Unified Gmail + Calendar MCP with built-in OAuth âœ…

### MCP Server Tools Reference

| Server | Purpose | Tools |
|--------|---------|-------|
| **perplexity** | Fast search + deep research with citations | `search`, `research` |
| **parallel-search** | Web search + content fetch (fallback option) | `web_search_preview`, `web_fetch` |
| **parallel-task** | Deep research tasks, report-style outputs | `createTask`, `getTask`, `listTasks` |
| **exa** | Web search, company research, URL content extraction (PRIMARY) | `search`, `findSimilar`, `getContents` |
| **firecrawl** | Scrape, crawl, extract (LAST RESORT ONLY) | `scrape`, `crawl`, `map`, `extract` |
| **playwright** | Browser automation for hard-to-scrape sites | `navigate`, `screenshot`, `click` |
| **notion** | Notion pages + databases | `createPage`, `updatePage`, `queryDatabase` |
| **nano-banana** | Image generation (Gemini 3.0) | `generate_image`, `edit_image`, `continue_editing` |
| **typefully** | Social media scheduling (Twitter, LinkedIn) âœ… | `create_draft`, `create_media_upload`, `get_media_status` |
| **gmail** | Unified Email + Calendar MCP âœ… | `search_emails`, `read_email`, `draft_email`, `send_email`, `list_calendar_events`, `create_calendar_event`, `authenticate` |

### 3-Tier Research Intensity System

| Level | Duration | Quality | Cost | Tools | Agents |
|-------|----------|---------|------|-------|--------|
| **Quick** | 10-30s | Basic | $0.01-0.05 | Built-in only | None |
| **Standard** | 2-5m | Good | $0.10-0.30 | MCPs | 2-4 Haiku |
| **Deep** | 5-15m | Excellent | $0.50-2.00 | All MCPs + Opus | 4-6 mixed |

**Quick**: WebSearch + WebFetch only. Fast fact-checking.

**Standard** [DEFAULT]: Perplexity, Exa (search + getContents) + 2-4 parallel Haiku agents.

**Deep**: Perplexity Deep, Parallel Task Deep + 4-6 agents including Opus.

**User Control**: `--quick`, `--standard`, `--deep` flags or inferred from query.

### Tiered Research Strategy

```
1. FAST SEARCH (seconds)
   â””â”€ perplexity search OR exa search
   â””â”€ Fallback: parallel-search web_search_preview
   â””â”€ Good for: quick facts, validation

2. DEEP RESEARCH (1-5 minutes)
   â””â”€ parallel-task createDeepResearch â†’ poll getResultMarkdown
   â””â”€ Fallback: perplexity research (deep)
   â””â”€ Good for: comprehensive reports

3. TARGETED EXTRACTION (as needed)
   â””â”€ exa getContents (PRIMARY)
   â””â”€ Fallback: parallel-search web_fetch
   â””â”€ Last resort: firecrawl scrape

4. HARD SCRAPING (last resort)
   â””â”€ playwright for JS-heavy sites
```

**Fallback Chain:**
- Web search: exa â†’ parallel-search â†’ WebSearch (built-in)
- URL content: exa getContents â†’ parallel-search web_fetch â†’ firecrawl (last resort) â†’ WebFetch
- Deep research: parallel-task â†’ perplexity (deep) â†’ multiple agents

### Key MCP Tool Patterns

**Parallel Task (Deep Research):**
```
mcp__parallel-task__createTask
  - prompt: string (research question)
  - Returns: task_id

mcp__parallel-task__getTask
  - task_id: string
  - Returns: { status, result } (poll until complete)
```

**Perplexity:**
```
mcp__perplexity__search
  - query: string
  - Returns: search results with citations

mcp__perplexity__research
  - query: string
  - depth: "basic" | "deep"
```

**Exa:**
```
mcp__exa__search
  - query: string
  - numResults: number

mcp__exa__findSimilar
  - url: string
```

**Parallel Search (Fallback):**
```
mcp__parallel-search__web_search_preview
  - objective: string (search objective)
  - search_queries: string[] (1-5 queries)
  - Returns: LLM-friendly search results

mcp__parallel-search__web_fetch
  - objective: string (optional, what to extract)
  - urls: string[] (max 10 URLs)
  - Returns: Extracted relevant content
```

**Firecrawl (LAST RESORT ONLY - use when exa and parallel-search fail):**
```
mcp__firecrawl__scrape
  - url: string
  - formats: ["markdown", "html"]

mcp__firecrawl__extract
  - url: string
  - schema: object (structured extraction)
```

**Nano Banana (Images):**
```
mcp__nano-banana__generate_image
  - prompt: string (detailed image description)

mcp__nano-banana__edit_image
  - imagePath: string (path to existing image)
  - prompt: string (edit instructions)

mcp__nano-banana__continue_editing
  - prompt: string (refinement instructions)
```

**Typefully (Social Media Scheduling):**

> **Preferred method:** Use direct API v2 calls via curl (see `.claude/skills/Content/workflows/schedule.md`)
> The MCP tools below may be outdated. Direct curl to `https://api.typefully.com/v2/` is more reliable.

```
# Direct API (preferred)
Authorization: Bearer $TYPEFULLY_API_KEY

GET  /v2/me                              # Current user
GET  /v2/social-sets                     # List accounts
POST /v2/social-sets/{id}/drafts         # Create draft
POST /v2/social-sets/{id}/media          # Upload media
GET  /v2/social-sets/{id}/media/{mid}    # Media status

# Available social sets (as of Jan 2026):
- 161806: @sgershuni (personal)
- 153901: @cyberFund_ (fund)
- 215751: @dAGIhouse

# MCP tools (may be outdated, use curl instead)
mcp__typefully__typefully_list_social_sets
mcp__typefully__typefully_get_social_set_details
mcp__typefully__typefully_create_draft
mcp__typefully__typefully_create_media_upload
mcp__typefully__typefully_get_media_status
```

Testing status: âœ… All core functionality validated via API v2
- Multi-platform posting (Twitter + LinkedIn): Tested
- Scheduled timing (ISO 8601): Tested
- Image upload with S3: Tested
- Draft-only mode: Tested

**Gmail (Unified Email + Calendar MCP):**
```
# Authentication (zero-config for new users)
mcp__gmail__authenticate
  - Opens browser for Google OAuth sign-in
  - Built-in OAuth credentials (no setup needed)
  - Single auth grants both Gmail AND Calendar access
  - Returns: { result: "Authentication process started..." }

mcp__gmail__check_auth_status
  - Returns: { authenticated: bool, message: string }

# Email Tools
mcp__gmail__search_emails
  - query: string (Gmail search syntax: from:, to:, subject:, after:, is:unread, etc.)
  - maxResults: number (optional, default: 10)
  - Returns: List of emails with sender, subject, date, message ID

mcp__gmail__list_emails
  - max_results: number (default: 10)
  - label: string (default: "INBOX")
  - Returns: List of emails

mcp__gmail__get_email
  - message_id: string
  - Returns: Full email content

# Calendar Tools
mcp__gmail__list_calendar_events
  - max_results: number (default: 10)
  - time_min: string (ISO 8601, optional)
  - time_max: string (ISO 8601, optional)
  - query: string (optional, free text search)
  - Returns: List of calendar events with times, attendees, links

mcp__gmail__create_calendar_event
  - summary: string (event title)
  - start_time: string (ISO 8601 or natural language like "tomorrow 3pm")
  - end_time: string (optional)
  - description: string (optional)
  - location: string (optional)
  - attendees: string[] (optional, email addresses)
  - Returns: { success, event_id, event_link }

Configuration:
- Server: Custom Python MCP at ~/gmail-mcp/
- Auth: OAuth 2.0 with BUILT-IN credentials (zero config)
- Project: serokell-v2 (Gmail API + Calendar API enabled)
- Token storage: ~/cyberman/tokens.json (encrypted)

Zero-config setup for new users:
1. Run `mcp__gmail__authenticate`
2. Click "Sign in with Google" in browser
3. Done - both Gmail and Calendar work

Advanced users can override with:
- credentials.json file in ~/gmail-mcp/
- GOOGLE_CLIENT_ID / GOOGLE_CLIENT_SECRET env vars

Integration with /deals/:
- Auto-detects company from sender domain
- Loads context from /deals/<company>/index.md
- Saves attachments to /deals/<company>/materials/

Testing status: âœ… Fully operational
- Email: list, search, read
- Calendar: list events, create events
```

---

## Workflow Patterns

### Research Workflow (Universal Orchestrator)

All research uses the **orchestrator workflow** (`.claude/skills/Research/workflows/orchestrator.md`):

```
1. INITIALIZE:
   â”œâ”€ Identify research type (Company | Tech | Market | Topic-Content | Topic-Investment)
   â”œâ”€ Determine intensity (Quick | Standard | Deep)
   â”œâ”€ Create workspace: /deals/<company>/research/MMDD-<slug>-YY/ OR /research/<topic>/MMDD-<slug>-YY/
   â””â”€ Select agents dynamically (see agent-selection-matrix.md)

2. GATHER (parallel agents - autonomous MCP calls):
   â”œâ”€ Spawn selected agents in parallel
   â”œâ”€ Each agent makes its own MCP calls (perplexity, exa, parallel-search)
   â”œâ”€ Each agent writes to: workspace/raw/agent-[name].md
   â””â”€ No MCP calls in main session (agents do everything)

3. REVIEW (Deep mode only):
   â”œâ”€ Spawn quality-reviewer agent
   â”œâ”€ Reads all agent outputs from workspace/raw/
   â”œâ”€ Identifies: completeness gaps, contradictions, shallow coverage
   â”œâ”€ If gaps found: re-spawn specific agents with refined prompts
   â””â”€ Max 1 iteration (no recursive quality reviews)

4. SYNTHESIZE:
   â”œâ”€ Spawn synthesizer agent
   â”œâ”€ Reads all agent outputs (including follow-ups)
   â”œâ”€ Applies appropriate lens (investment vs content)
   â””â”€ Writes to: workspace/report.md

5. OUTPUT:
   â”œâ”€ Final synthesis: workspace/report.md
   â”œâ”€ All agent outputs preserved in: workspace/raw/
   â””â”€ Log to: /.serokell/logs/MMDD-YY.md
```

**Workspace Structure:**
```
MMDD-<slug>-YY/
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ agent-company-researcher.md
â”‚   â”œâ”€â”€ agent-market-researcher.md
â”‚   â”œâ”€â”€ agent-financial-researcher.md
â”‚   â”œâ”€â”€ agent-quality-reviewer.md (deep only)
â”‚   â””â”€â”€ agent-[name]-followup.md (if quality loop triggered)
â””â”€â”€ report.md (final synthesis)
```

**Agent Selection Matrix:**
- **Company DD**: company + market + financial (standard), +team +quality-reviewer (deep)
- **Technology**: tech + market (standard), +company +quality-reviewer (deep)
- **Market**: market + financial (standard), +company +quality-reviewer (deep)
- **Topic-Content**: content-researcher (standard), +quality-reviewer (deep)
- **Topic-Investment**: investment-researcher + market (standard), +financial +quality-reviewer (deep)

See `.claude/skills/Research/shared/agent-selection-matrix.md` for complete matrix.

**Key Principles:**
- Agents do ALL data gathering (autonomous MCP usage)
- No redundancy (main session doesn't pre-gather data)
- Dynamic selection based on type and intensity
- Quality loop ensures completeness (deep mode only)

### Content Architecture

Content creation follows a layered architecture:

```
COMMAND (serokell-essay, cyber-tweet, etc.)
    â”‚
    â–¼
WORKFLOW (essay.md, tweet.md, telegram-post.md)
    â”‚
    â”œâ”€â–º LOADS: context/style/voice-identity.md (shared persona)
    â”‚
    â””â”€â–º LOADS: context/style/writing-style-[en|ru].md (language-specific)
```

**Context Files:**
| File | Purpose |
|------|---------|
| `context/style/voice-identity.md` | Shared persona, tone, anti-patterns |
| `context/style/writing-style-en.md` | English: essay structure, tweet format |
| `context/style/writing-style-ru.md` | Russian: Telegram format, Russian rules |

### Content Workflow (Telegram Posts)

Russian posts (@cryptoEssay) + English translations:

```
1. ASSESS
   â””â”€ Light research if data claims need verification

2. DRAFT (Russian)
   â””â”€ Load: context/style/voice-identity.md + writing-style-ru.md
   â””â”€ Strong hook, short paragraphs, no LLM phrases
   â””â”€ Plain text (no markdown for Telegram)

3. TRANSLATE (English)
   â””â”€ Load: context/style/writing-style-en.md for English rules
   â””â”€ Native English, not literal translation

4. OUTPUT
   â””â”€ Saved to /content/posts/MMDD-<slug>-YY.md
   â””â”€ Log to /.serokell/logs/MMDD-YY.md
```

**Workflow**: `.claude/skills/Content/workflows/telegram-post.md`

### Content Workflow (Essays)

Long-form English content:

```
1. ASSESS
   â””â”€ Verify factual claims if needed
   â””â”€ Load source files (@ references)

2. DRAFT
   â””â”€ Load: context/style/voice-identity.md + writing-style-en.md
   â””â”€ Hook â†’ Stakes â†’ Mechanism â†’ Turn â†’ Landing
   â””â”€ 500-2500 words depending on complexity

3. REVIEW
   â””â”€ Present draft for user feedback

4. POLISH
   â””â”€ Apply feedback, maintain voice

5. OUTPUT
   â””â”€ Saved to /content/essays/MMDD-<slug>-YY.md
   â””â”€ Log to /.serokell/logs/MMDD-YY.md
```

**Workflow**: `.claude/skills/Content/workflows/essay.md`

### Content Workflow (Twitter Threads)

English tweets and threads:

```
1. ASSESS
   â””â”€ Verify factual claims if needed

2. DRAFT
   â””â”€ Load: context/style/voice-identity.md + writing-style-en.md
   â””â”€ Hook patterns: "how to X", "why X doesn't work"
   â””â”€ One sentence per line, lists for structure

3. FORMAT
   â””â”€ Single tweet or thread (3-10 tweets)
   â””â”€ Engagement: question OR controversial stance

4. OUTPUT
   â””â”€ Saved to /content/tweets/MMDD-<slug>-YY.md
   â””â”€ Log to /.serokell/logs/MMDD-YY.md
```

**Workflow**: `.claude/skills/Content/workflows/tweet.md`

### Social Media Scheduling Workflow

Schedule content to Twitter and/or LinkedIn via Typefully:

```
1. LOAD CONTENT
   â””â”€ Read existing content from /content/tweets|posts|essays/
   â””â”€ Extract appropriate section (Tweet Text, English translation, etc.)

2. SELECT PLATFORMS
   â””â”€ Ask user: Twitter / LinkedIn / Both
   â””â”€ Build platform config with enabled flags

3. SELECT TIMING
   â””â”€ Ask user: Now / Queue / Schedule
   â””â”€ Map to: "now" | "next-free-slot" | ISO-8601 timestamp

4. HANDLE MEDIA (optional) âœ… Validated
   â””â”€ If --image flag provided:
      â”œâ”€ Call: mcp__typefully__typefully_create_media_upload
      â”œâ”€ Upload to S3 via presigned URL (curl PUT, no Content-Type header)
      â”œâ”€ Poll: mcp__typefully__typefully_get_media_status until "ready"
      â””â”€ Capture media_id UUID for posts array

5. CREATE DRAFT
   â””â”€ Call: mcp__typefully__typefully_create_draft
   â””â”€ Social set: <social-set-id> (<account-name> @<username>)
   â””â”€ Platform config: { x/linkedin: { enabled, posts: [{text, media_ids}] } }
   â””â”€ Returns: draft ID, status, Typefully URL

6. CONFIRM & LOG
   â””â”€ Display: Platforms, timing, Typefully URL
   â””â”€ Log to /.serokell/logs/MMDD-<slug>-YY.md
   â””â”€ Local file remains unchanged (archive preserved)
```

**Command**: `/serokell-schedule @content/file.md --image @content/image.png`
**Workflow**: `.claude/skills/Content/workflows/schedule.md`
**Status**: âœ… Production ready (tested: multi-platform, scheduling, images)

### Image Generation Workflow

Main session pipeline with automatic style inference:

```
1. INFER STYLE from request keywords:
   - info: "infographic", "diagram", "process", "flow", "comparison"
   - mural: "transformation", "sacred", "dissolution", "empire"
   - cyberpunk: "future", "atmospheric", "liminal" (default)

2. EXTRACT core idea (one sentence)

3. CREATE visual approach:
   - Info: diagram structure (icon, comparison, process, hierarchy)
   - Artistic: visual metaphor (balanced, not too literal/abstract)

4. LOAD style files from context/img-styles/

5. BUILD prompt using template from _shared.md

6. GENERATE via mcp__nano-banana__generate_image

7. SAVE to /content/images/MMDD-<slug>-YY.png
```

**Multiple images**: Call MCP in parallel for independent images.

**Style files** (`context/img-styles/`):
- `_shared.md` - Common rules, prompt template, universal avoids
- `cyberpunk.md` - Grounded futurism, Blade Runner aesthetic
- `mural.md` - Sacred transformation, particle dissolution
- `info.md` - Minimal infographics, handdrawn clarity

**Adding new styles**: Create `context/img-styles/{name}.md` with palette, elements, keywords.

**Command**: `/serokell-image "concept"` or `/serokell-image @source.md "visualize"`
**Workflow**: `.claude/skills/Content/workflows/image.md`

**Info Style Concept Engineering** (for diagrams/infographics):
- Workflow includes concept engineering step before generation
- Extracts core insight, identifies visual mechanism, self-critiques
- Post-generation critique with 5-point checklist (squint, text, background, contrast, usability)
- One regeneration allowed if critique fails
- Guide: `context/img-styles/info-concept-guide.md`
- Evals: `.claude/skills/Content/evals/info-style/` (3 evals, all passing)

### Baoyu Infographic Skill

Professional infographic generator with **20 layouts Ã— 17 styles**. Analyzes content, recommends layoutÃ—style combinations, generates publication-ready infographics via nano-banana MCP.

```
1. SETUP: Load EXTEND.md preferences (project-level or ~/.baoyu-skills/)
2. ANALYZE: Content â†’ analysis.md (topic, data type, complexity, audience)
3. STRUCTURE: Transform into structured-content.md (verbatim data, visual elements)
4. RECOMMEND: 3-5 layoutÃ—style combinations based on content analysis
5. CONFIRM: Single AskUserQuestion for combination + aspect + language
6. PROMPT: Combine layout def + style def + base template + structured content
7. GENERATE: via mcp__nano-banana__generate_image
8. OUTPUT: Save to vault with summary
```

**Output**:
```
~/SerokellSalesVault/private/content/infographics/{topic-slug}/
â”œâ”€â”€ source-{slug}.{ext}
â”œâ”€â”€ analysis.md
â”œâ”€â”€ structured-content.md
â”œâ”€â”€ prompts/infographic.md
â””â”€â”€ infographic.png
```
Final image also copied to: `~/SerokellSalesVault/private/content/images/MMDD-{slug}-YY.png`

**Command**: `/baoyu-infographic path/to/content.md --layout hierarchical-layers --style technical-schematic`
**Skill**: `.claude/skills/baoyu-infographic/SKILL.md`

### DD Memo Workflow

```
1. GATHER
   â””â”€ Load: /deals/<company>/research/* (all research)
   â””â”€ Load: /deals/<company>/index.md
   â””â”€ Load: @context/investment-philosophy.md
   â””â”€ Load: @context/MEMO_template.md

2. ANALYZE (Opus)
   â””â”€ Deep strategic analysis
   â””â”€ Apply investment rubric

3. WRITE (Sonnet)
   â””â”€ Fill template structure

4. OUTPUT
   â””â”€ /deals/<company>/memo/memo.md
   â””â”€ Log action
```

### GTD Workflow (Autonomous Task Execution)

Process GTD.md items autonomously with entity context:

```
1. PARSE
   â””â”€ Read GTD.md â†’ extract items from # Next section

2. CLASSIFY (per item)
   â””â”€ Match patterns against routing table:
      - "ask for call", "message", "email" â†’ outreach workflow
      - "call with", "meeting", "<> X" â†’ call-prep workflow
      - "podcast" â†’ podcast workflow
      - company name, "research" â†’ research workflow
      - unknown â†’ best judgment

3. ENTITY LOOKUP
   â””â”€ Query database: `bun scripts/db/query.ts find-entity "<name>"`
   â””â”€ Load context: `bun scripts/db/query.ts entity <slug> --json`
   â””â”€ Extract contact info, previous interactions, pending items

4. PLAN (default behavior)
   â””â”€ Show plan for each item before executing
   â””â”€ Ask for approval: "Execute? [Y/n/select]"

5. EXECUTE
   â””â”€ Execute each task sequentially (one at a time)
   â””â”€ Agent follows selected workflow
   â””â”€ Staged execution: autonomous work + pending approvals

6. OUTPUT
   â””â”€ /content/work/MMDD-<slug>.md (one file per task)
   â””â”€ Format: context + draft + pending actions + log
   â””â”€ Log to learnings.md
```

**Command**: `/serokell-gtd`, `/serokell-gtd --count 3`, `/serokell-gtd --execute`
**Workflow**: `.claude/skills/GTD/SKILL.md`

**Output File Format:**
```markdown
# Task: [Description]

**Status:** Pending Approval | Completed | Incomplete
**Created:** YYYY-MM-DD HH:MM
**Workflow:** [which workflow]

## Context
[Entity info, previous calls, deal context]

## Draft
[Message/agenda/questions]

## Pending Actions
- [ ] Send via Gmail to email@example.com
- [ ] Alternative: Telegram @handle

## Execution Log
- HH:MM - [action taken]
```

---

## Database Indexer

The database indexer provides a unified SQLite-based context graph for all entities, interactions, and extracted items.

### Architecture

```
Sources:                              SQLite Database:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
/deals/*/                        â”€â”€â”
/context/calls/*/                â”€â”€â”¼â”€â”€â–º  entities (people, companies, products)
/context/entities/*.md (sparse)  â”€â”€â”¤     interactions (calls, emails, telegram)
/context/telegram/*.md           â”€â”€â”¤     extracted_items (promises, actions, decisions)
/context/emails/*/               â”€â”€â”˜     entity_aliases (for deduplication)
```

### Database Schema (SQLite v2.1)

```sql
-- Core tables (5 tables, ~51 columns)
entities           -- People, companies, products, groups
entity_aliases     -- Name variations for deduplication
interactions       -- Calls, emails, telegram messages
extracted_items    -- Promises, action items, decisions, questions, metrics
batch_runs         -- Indexer run logs

-- Key features
- Full-text search via FTS5 virtual table
- Fuzzy name matching via TypeScript Levenshtein distance
- Temporal queries via ISO-8601 timestamps
- JSON arrays for participant storage (json_each() for queries)
- WAL mode for performance
```

### Scripts Structure

```
scripts/db/
â”œâ”€â”€ schema-sqlite.sql       # SQLite schema with FTS5
â”œâ”€â”€ client-sqlite.ts        # SQLite client (bun:sqlite)
â”œâ”€â”€ init.ts                 # Create database and tables
â”œâ”€â”€ index.ts                # Main batch indexer
â”œâ”€â”€ extract-llm.ts          # Claude Haiku extraction runner
â”œâ”€â”€ entity-resolver.ts      # TypeScript entity matching with Levenshtein
â”œâ”€â”€ query.ts                # Query interface + CLI
â”œâ”€â”€ extractors/
â”‚   â”œâ”€â”€ calls.ts            # Parse /context/calls/
â”‚   â”œâ”€â”€ emails.ts           # Parse /context/emails/
â”‚   â”œâ”€â”€ telegram.ts         # Parse /context/telegram/
â”‚   â”œâ”€â”€ entities.ts         # Parse manual entity files
â”‚   â””â”€â”€ deals.ts            # Parse /deals/ as company entities
â””â”€â”€ prompts/
    â”œâ”€â”€ types.ts            # Shared extraction types
    â”œâ”€â”€ call-extraction.ts  # Call extraction prompt
    â”œâ”€â”€ email-extraction.ts # Email extraction prompt
    â””â”€â”€ telegram-extraction.ts # Telegram extraction prompt
```

### Entity Resolution

TypeScript-based multi-stage matching using Levenshtein distance:

| Stage | Match Type | Confidence | Action |
|-------|-----------|------------|--------|
| 0 | User identity (configured aliases) | 1.0 | Return user entity (configured slug) |
| 1 | Blocked name (Speaker, Unknown) | - | Skip (return `_blocked_`) |
| 2 | Email exact match | 1.0 | Return existing entity |
| 3 | Telegram handle match | 1.0 | Return existing entity |
| 4 | Fuzzy name match (>0.7 Levenshtein similarity) | 0.7-0.9 | Return existing, add alias |
| 5 | No match found | - | Create new candidate entity |

**User Identity Handling (v1.1):**
- Configured aliases (including "Me") â†’ resolve to the user entity slug
- User identity is checked FIRST before any database queries
- Items with user as owner/target correctly link to user entity
- Prevents creating duplicate user entities

**Blocked Entity Names (v1.1):**
- Generic labels are blocked: "Speaker", "Unknown", "Participant", "Caller", etc.
- User identity names are also blocked from entity creation
- Returns `_blocked_` slug which is filtered out of participants arrays
- Prevents pollution of entity database with meaningless entities

**Conservative Context Updates (v1.1):**
- Company/role info is ONLY updated from EXACT matches (email, telegram, alias)
- Fuzzy matches do NOT update company/role (prevents entity conflation)
- Example: "Dima" fuzzy-matching to "Dima Khanarin" won't update Khanarin's company

**Two-tier Entity System (v1.1):**
- Confirmed entities: `is_candidate = FALSE` (high confidence)
- Candidate entities: `is_candidate = TRUE` (extracted from calls/emails without match)
- Query `list-candidates` to review and merge candidates
- Prevents low-confidence entities from polluting the main database

**Type normalization** handles LLM variations:
- `org`, `organization`, `startup`, `fund` â†’ `company`
- `chat`, `channel`, `community` â†’ `group`
- `service`, `tool`, `platform`, `technology` â†’ `product`

### LLM Extraction

Claude Haiku extracts structured items from interactions:

| Type | Description | Example |
|------|-------------|---------|
| `promise` | Commitment to do something | "I'll send you the deck" |
| `action_item` | Task needing completion | "Follow up on pricing" |
| `decision` | Conclusion reached | "We agreed to proceed with X" |
| `question` | Open question | "Need to confirm timeline" |
| `metric` | Business numbers | "500K ARR, 10 employees" |
| `deal_mention` | Deal reference | "John introduced Acme Corp" |
| `entity_context` | What someone is building | "Working on AI agents" |

**Provenance (v1.1):** Each item includes:
- `source_quote` - Verbatim quote from source (10-50 words)
- `source_span` - Line numbers (calls) or timestamp (telegram)
- `trust_level` - high/medium/low based on confidence + linkage

**Type Validation (v1.1):**
- Invalid types are automatically mapped: `info`/`context`/`note` â†’ `entity_context`
- `task`/`todo` â†’ `action_item`, `commitment` â†’ `promise`
- Unknown types are skipped with warning

**User Identity Handling (v1.1):**
- LLM prompt instructs to use the configured owner name for user identity
- Extract-llm resolves owner/target names through user identity check
- User entity is auto-created if needed (prevents FK constraint errors)

**Cost**: ~$0.01/interaction using Claude 3.5 Haiku

### Query Interface

```bash
# Entity lookup
bun scripts/db/query.ts entity john-smith --detailed
bun scripts/db/query.ts find-entity john@example.com
bun scripts/db/query.ts find-entity @johndoe

# Search
bun scripts/db/query.ts search-entities "john" --type person
bun scripts/db/query.ts search "AI infrastructure" --since 2026-01-01

# Deal attribution
bun scripts/db/query.ts who-shared acme-corp

# Temporal context
bun scripts/db/query.ts what-doing john-smith "3 months ago"
bun scripts/db/query.ts timeline john-smith

# Pending items
bun scripts/db/query.ts pending --owner me --type promise

# Database status
bun scripts/db/query.ts status
bun scripts/db/query.ts status --json
```

### Commands

| Command | Purpose |
|---------|---------|
| `/serokell-reindex` | Full database rebuild |
| `/serokell-reindex --status` | Show database status |
| `/serokell-reindex --extract` | Index + LLM extraction |
| `/serokell-reindex --extract-only` | Run extraction on indexed interactions |

### Freshness Checking

SessionStart hook checks database freshness:
1. Queries `batch_runs` table for last run timestamp
2. If >24 hours old, warns user to run `/serokell-reindex`
3. If database unavailable, shows warning to start PostgreSQL

### Entity Files (Sparse)

Only create entity files when you need to add info not available elsewhere:

```markdown
# Dan Meissler
**Type:** person
**Aliases:** Dan M, Meissler

## Contact
- Email: dan@example.com
- Telegram: @danmeissler

## Notes
[Context about this person]
```

**Location:** `/context/entities/people/` or `/context/entities/orgs/`

### Prerequisites

```bash
# Initialize SQLite database (no external server needed)
bun scripts/db/init.ts

# Reset and reinitialize
bun scripts/db/init.ts --reset

# Check status
bun scripts/db/init.ts --status

# Run indexer
bun scripts/db/index.ts

# Run with LLM extraction
bun scripts/db/index.ts --extract

# Environment variables (.env)
SEROKELL_ANTHROPIC_KEY=sk-ant-...  # For LLM extraction
SEROKELL_USER_NAME=Your Name      # For identity resolution
SEROKELL_USER_OWNER_NAME=YourName # For owner/target labeling
```

**Database location**: `.serokell/serokell.sqlite` (in app root for legacy mode) or `~/SerokellSalesVault/private/.serokell/db/serokell.sqlite` (vault mode)

---

## Project System

Projects are multi-week initiatives that need their own context, research, and artifacts. They differ from deals (investment opportunities) and are tracked in both GTD.md and optional `/projects/` folders.

### GTD.md Integration

Projects are `# headings` in GTD.md (not `## headings`). Tasks under a heading belong to that project.

```markdown
# scheduler
- Task 1 for scheduler project
- Task 2 for scheduler project

# context-graph
- Task 1 for context graph
```

**Reserved headings (not projects):** `# Next`, `# Someday`, `# IC`, `# Skip`

### When to Create /projects/ Folder

| Scenario | GTD-only | Create /projects/ |
|----------|----------|-------------------|
| Few tasks, clear scope | Yes | |
| Needs research artifacts | | Yes |
| Multiple collaborators | | Yes |
| External deliverables | | Yes |
| Spans 2+ months | | Yes |
| Has milestones/phases | | Yes |

### Project Folder Structure

```
/projects/<slug>/
â””â”€â”€ .serokell/
    â””â”€â”€ context.md    # Required: goals, status, collaborators
```

Only `.serokell/context.md` is required. Organize the rest as needed for your project.

### Project Context Template

```markdown
# Project: [Display Name]

**Slug:** [slug matching GTD # heading]
**Status:** [Planning | Active | On Hold | Completed | Archived]
**Type:** [Event | Accelerator | Product | Initiative]
**Started:** YYYY-MM-DD
**Target:** YYYY-MM-DD (optional)
**Lead:** [Person]

## Goal
[One paragraph: what does success look like?]

## Key Results
- [ ] KR1: Measurable outcome

## Collaborators
| Person | Role | Contact |
|--------|------|---------|

## Timeline / Milestones
| Milestone | Target | Status |
|-----------|--------|--------|

## Log
### YYYY-MM-DD
- [What happened]
```

### Projects vs Deals

| Aspect | /deals | /projects |
|--------|--------|-----------|
| **Purpose** | Evaluate external investment | Execute internal initiative |
| **Ownership** | External founders | We own the project |
| **Outcome** | Invest / Pass decision | Deliverable completion |
| **Primary artifacts** | Research, memo | Content, decks, tools |
| **Task source** | Ad-hoc, call follow-ups | GTD.md `# heading` |

Rule: If it's about **deciding to invest in external entity**, it's a deal. Everything else is a project.

### Project Commands

| Command | Purpose |
|---------|---------|
| `/serokell-init-project "Name"` | Create project folder with context template |
| `/serokell-project slug` | Show project status and tasks |
| `/serokell-projects` | List all projects |
| `/serokell-gtd --project slug` | Process tasks for specific project |

### Context Auto-Loading

When user mentions a project:
1. Check if `/projects/<slug>/` exists (try kebab-case conversion)
2. If exists, read `/projects/<slug>/.serokell/context.md`
3. Also check GTD.md for tasks under the `# <slug>` heading
4. Incorporate context into response

---

## Folder Structure

```
project-root/
â”œâ”€â”€ vault -> ~/SerokellSalesVault           # Symlink to user data (gitignored, shows private/ and shared/)
â”œâ”€â”€ .mcp.json                       # MCP server configuration (uses ${VAR} for env vars)
â”œâ”€â”€ .claude/
â”‚   â”œâ”€â”€ settings.json           # Hook wiring, permissions
â”‚   â”œâ”€â”€ napkin.md               # Self-improvement log (mistakes, patterns, preferences)
â”‚   â”œâ”€â”€ skills/                 # Organized workflows (convention)
â”‚   â”‚   â”œâ”€â”€ Research/
â”‚   â”‚   â”‚   â”œâ”€â”€ workflows/
â”‚   â”‚   â”‚   â”œâ”€â”€ shared/
â”‚   â”‚   â”‚   â””â”€â”€ evals/
â”‚   â”‚   â”œâ”€â”€ Browse/
â”‚   â”‚   â”‚   â””â”€â”€ workflows/
â”‚   â”‚   â”œâ”€â”€ Content/
â”‚   â”‚   â”‚   â””â”€â”€ workflows/
â”‚   â”‚   â”œâ”€â”€ DDMemo/
â”‚   â”‚   â”‚   â””â”€â”€ workflows/
â”‚   â”‚   â”œâ”€â”€ GTD/
â”‚   â”‚   â”‚   â”œâ”€â”€ SKILL.md
â”‚   â”‚   â”‚   â”œâ”€â”€ workflows/
â”‚   â”‚   â”‚   â””â”€â”€ learnings.md
â”‚   â”‚   â””â”€â”€ Self-improve/
â”‚   â”‚       â””â”€â”€ SKILL.md        # Always-active napkin for mistakes/patterns
â”‚   â”œâ”€â”€ agents/                 # Agent profiles for Task tool
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â””â”€â”€ load-context.ts     # SessionStart hook
â”‚   â””â”€â”€ commands/               # Slash commands
â”œâ”€â”€ context/                    # Core context files (symlinked from vault)
â”‚   â”œâ”€â”€ who-am-i.md
â”‚   â”œâ”€â”€ organization.md
â”‚   â”œâ”€â”€ investment-philosophy.md
â”‚   â”œâ”€â”€ style/                  # Writing style guides
â”‚   â”‚   â”œâ”€â”€ voice-identity.md   # Shared persona, tone
â”‚   â”‚   â”œâ”€â”€ writing-style-en.md # English (essays, tweets)
â”‚   â”‚   â””â”€â”€ writing-style-ru.md # Russian (Telegram)
â”‚   â”œâ”€â”€ img-styles/             # Image style definitions
â”‚   â”‚   â”œâ”€â”€ _shared.md          # Common rules for all styles
â”‚   â”‚   â”œâ”€â”€ cyberpunk.md        # Grounded futurism (Blade Runner)
â”‚   â”‚   â”œâ”€â”€ mural.md            # Sacred transformation
â”‚   â”‚   â””â”€â”€ info.md             # Minimal infographics
â”‚   â”œâ”€â”€ MEMO_template.md
â”‚   â”œâ”€â”€ calls/                  # Granola call transcripts
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â””â”€â”€ MMDD-title-YY/
â”‚   â”œâ”€â”€ telegram/               # Per-person conversation logs (GramJS)
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ <person-slug>.md    # Persistent conversation file
â”‚   â”‚   â””â”€â”€ <group-slug>.md     # Group chats too
â”‚   â”œâ”€â”€ emails/                 # Indexed emails for morning brief
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ .state.json         # Dedup state (messageIds)
â”‚   â”‚   â””â”€â”€ YYYY-MM-DD_from-subject/
â”‚   â”‚       â”œâ”€â”€ metadata.json   # Email metadata + summary
â”‚   â”‚       â””â”€â”€ body.md         # Email content
â”‚   â””â”€â”€ entities/               # Entity context (indexed in SQLite)
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ people/             # Manual entity files (optional)
â”‚       â””â”€â”€ orgs/               # Manual entity files (optional)
â”œâ”€â”€ deals/                      # Deal folders
â”‚   â””â”€â”€ <company-slug>/
â”‚       â”œâ”€â”€ index.md            # DataView frontmatter + full deal context
â”‚       â”œâ”€â”€ .serokell/
â”‚       â”‚   â””â”€â”€ scratchpad/
â”‚       â”œâ”€â”€ research/
â”‚       â”‚   â”œâ”€â”€ MMDD-<slug>-YY.md      # Main synthesis
â”‚       â”‚   â””â”€â”€ raw/                    # Raw agent/MCP data
â”‚       â”‚       â”œâ”€â”€ agent-*.md
â”‚       â”‚       â””â”€â”€ mcp-*.md
â”‚       â””â”€â”€ memo/
â”œâ”€â”€ research/                   # Topic/market/tech research
â”‚   â””â”€â”€ <topic-slug>/
â”‚       â”œâ”€â”€ MMDD-<slug>-YY.md          # Main synthesis
â”‚       â””â”€â”€ raw/                        # Raw agent/MCP data
â”‚           â”œâ”€â”€ agent-*.md
â”‚           â””â”€â”€ mcp-*.md
â”œâ”€â”€ projects/                   # Multi-week initiatives
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ <project-slug>/
â”‚       â””â”€â”€ .serokell/
â”‚           â””â”€â”€ context.md             # Goals, status, collaborators
â”œâ”€â”€ content/                    # Generated content
â”‚   â”œâ”€â”€ posts/              # Telegram posts (RU) + Twitter (EN)
â”‚   â”œâ”€â”€ tweets/             # Twitter-native threads (EN)
â”‚   â”œâ”€â”€ essays/
â”‚   â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ ideas/              # Browse-discovered topic ideas
â”‚   â”œâ”€â”€ briefs/             # Morning briefs (MMDD-YY.md)
â”‚   â””â”€â”€ work/               # GTD task outputs (MMDD-<slug>.md)
â”œâ”€â”€ config/                     # Configuration files
â”‚   â”œâ”€â”€ leverage-rules.yaml     # Strategic leverage scoring rules
â”‚   â””â”€â”€ launchd/                # macOS scheduling plists (templates)
â”‚       â”œâ”€â”€ com.serokell.brief-server.plist.example
â”‚       â””â”€â”€ com.serokell.morning-brief.plist.example
â””â”€â”€ scripts/                    # Utility scripts
    â”œâ”€â”€ extract-granola.ts
    â”œâ”€â”€ telegram-gramjs.ts      # GramJS MTProto client for Telegram
    â”œâ”€â”€ telegram-save-drafts.ts # Save AI drafts to Telegram
    â”œâ”€â”€ brief-parser.ts         # Markdown â†’ JSON brief parser
    â”œâ”€â”€ brief-server.ts         # Hono HTTP server (port 3847)
    â”œâ”€â”€ morning-brief.sh        # Orchestrator script
    â”œâ”€â”€ install-brief.sh        # Installation script
    â”œâ”€â”€ web-brief/              # React + Tailwind brief/explorer/unstuck UI
    â”‚   â”œâ”€â”€ src/
    â”‚   â”‚   â”œâ”€â”€ App.tsx
    â”‚   â”‚   â”œâ”€â”€ types.ts
    â”‚   â”‚   â””â”€â”€ api.ts
    â”‚   â””â”€â”€ dist/               # Production build
    â””â”€â”€ db/                     # SQLite database indexer
        â”œâ”€â”€ schema-sqlite.sql   # SQLite schema with FTS5
        â”œâ”€â”€ client-sqlite.ts    # SQLite client (bun:sqlite)
        â”œâ”€â”€ init.ts             # Schema initialization
        â”œâ”€â”€ index.ts            # Main batch indexer
        â”œâ”€â”€ extract-llm.ts      # Claude Haiku extraction
        â”œâ”€â”€ entity-resolver.ts  # TypeScript Levenshtein matching
        â”œâ”€â”€ query.ts            # Query interface + CLI
        â”œâ”€â”€ extractors/         # Source-specific parsers
        â”‚   â”œâ”€â”€ calls.ts
        â”‚   â”œâ”€â”€ emails.ts
        â”‚   â”œâ”€â”€ telegram.ts
        â”‚   â”œâ”€â”€ entities.ts
        â”‚   â””â”€â”€ deals.ts
        â””â”€â”€ prompts/            # LLM extraction prompts
            â”œâ”€â”€ types.ts
            â”œâ”€â”€ call-extraction.ts
            â”œâ”€â”€ email-extraction.ts
            â””â”€â”€ telegram-extraction.ts
```

---

## Environment Variables

```bash
# User Identity (required)
SEROKELL_USER_NAME=Your Name
SEROKELL_USER_OWNER_NAME=YourName
SEROKELL_USER_SLUG=your-name
SEROKELL_USER_ALIASES=Me,Your Name

# LLM Extraction (required for /serokell-reindex --extract)
SEROKELL_ANTHROPIC_KEY=sk-ant-...

# Web Research (required)
PERPLEXITY_API_KEY=pplx-...
EXA_API_KEY=...
PARALLEL_API_KEY=...

# Extraction (required)
FIRECRAWL_API_KEY=fc-...

# Image Generation (required for content)
GEMINI_API_KEY=...

# Telegram (required for /serokell-telegram)
TELEGRAM_API_ID=...              # Get from https://my.telegram.org/apps
TELEGRAM_API_HASH=...            # Get from https://my.telegram.org/apps

# Documents (optional but recommended)
NOTION_TOKEN=secret_...
```

---

## Hook System

| Hook | Event | Action |
|------|-------|--------|
| `load-context.ts` | SessionStart | Inject identity + deal-loading instructions + database freshness check |

### SessionStart Hook

The hook injects:
- User identity from `context/who-am-i.md`
- Organization context from `context/organization.md`
- Database freshness check (warns if >24 hours stale)
- Deal context auto-loading instructions
- Logging requirement reminder

**Database Freshness Check:**
1. Queries `batch_runs` table via `bun scripts/db/query.ts status --json`
2. If database available and last run >24h, shows warning to run `/serokell-reindex`
3. If database not initialized, shows warning to run `/serokell-reindex`

Configuration in `.claude/settings.json`:
```json
{
  "hooks": {
    "SessionStart": [
      {
        "type": "command",
        "command": "bun .claude/hooks/load-context.ts"
      }
    ]
  }
}
```

---

## Logging System

**Unified logging location**: `~/SerokellSalesVault/private/.serokell/logs/`

All logs are stored in the vault for portability and backup. Path resolved via `scripts/paths.ts:getLogsPath()`.

### Log File Types

| Pattern | Source | Purpose |
|---------|--------|---------|
| `MMDD-YY.md` | Workflows, Claude | Daily activity logs (workflow completions, MCP calls) |
| `morning-brief.log` | morning-brief.sh | Brief generation run logs |
| `reindex.log` | reindex.sh | Database indexing run logs |
| `brief-server.out.log` | LaunchD | Brief server stdout |
| `brief-server.err.log` | LaunchD | Brief server stderr |
| `morning-brief.out.log` | LaunchD | Morning brief daemon stdout |
| `morning-brief.err.log` | LaunchD | Morning brief daemon stderr |
| `reindex.out.log` | LaunchD | Reindex daemon stdout |
| `reindex.err.log` | LaunchD | Reindex daemon stderr |

### Path Resolution

**Shell scripts** source `scripts/get-log-path.sh` which exports `VAULT_LOG_DIR`:
```bash
source "$SCRIPT_DIR/get-log-path.sh"
LOG_FILE="$VAULT_LOG_DIR/my-script.log"
```

**TypeScript scripts** use `scripts/paths.ts`:
```typescript
import { getLogsPath } from './paths'
const logDir = getLogsPath()  // ~/SerokellSalesVault/private/.serokell/logs
```

**LaunchD plists** use `__VAULT_LOGS__` placeholder (substituted by `install-brief.sh`).

### Daily Activity Log Format (MMDD-YY.md)

**Workflow completion:**
```markdown
## HH:MM | category | type | subject
- Workflow: workflow-name
- Intensity: Quick | Standard | Deep (for research)
- Duration: Xm Ys
- Output: /path/to/output.md
- Agents: agent1, agent2, agent3 (X/Y success)
- MCPs used: perplexity, exa, exa-contents, parallel-search, etc.
- Confidence: High | Medium | Low (for research)

---
```

**MCP call:**
```markdown
## HH:MM | mcp | [server-name] | [operation]
- Query/URL: [request details]
- Status: Success | Failed
- Error: [if failed]
- Fallback: [if used]
- Duration: Xs
- Cost: $X.XX (estimate)

---
```

**Full logging specification**: `.claude/skills/Research/shared/logging.md`